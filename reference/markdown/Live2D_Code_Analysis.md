# Live2D VTuber System ì½”ë“œ ë¶„ì„ ë³´ê³ ì„œ

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” Open-LLM-VTuber í”„ë¡œì íŠ¸ì˜ Live2D ê´€ë ¨ ì½”ë“œë¥¼ ìƒì„¸íˆ ë¶„ì„í•˜ê³ , ìºë¦­í„° ì‹¤í–‰ ë©”ì»¤ë‹ˆì¦˜ê³¼ ë™ì‘ ë°©ì‹ì„ ì„¤ëª…í•©ë‹ˆë‹¤. ë¶„ì„ëœ ë‚´ìš©ì€ Fortune VTuber í”„ë¡œì íŠ¸ êµ¬í˜„ì— ì§ì ‘ ì°¸ê³ í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì „ì²´ êµ¬ì¡°ë„

```
Frontend (React + Live2D)
        â†“ WebSocket
Backend (FastAPI + Python)
        â†“
Service Context Manager
        â†“
â”œâ”€â”€ Live2D Model Manager
â”œâ”€â”€ WebSocket Handler  
â”œâ”€â”€ Conversation Handler
â”œâ”€â”€ TTS Integration
â””â”€â”€ Agent System
```

## ğŸ“ í•µì‹¬ íŒŒì¼ êµ¬ì¡°

```
reference/
â”œâ”€â”€ src/open_llm_vtuber/
â”‚   â”œâ”€â”€ live2d_model.py          # Live2D ëª¨ë¸ ê´€ë¦¬ í•µì‹¬ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ websocket_handler.py     # WebSocket í†µì‹  ì²˜ë¦¬
â”‚   â”œâ”€â”€ server.py               # FastAPI ì„œë²„ ì„¤ì •
â”‚   â”œâ”€â”€ routes.py               # API ë¼ìš°íŒ…
â”‚   â””â”€â”€ service_context.py      # ì„œë¹„ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
â”œâ”€â”€ live2d-models/              # Live2D ëª¨ë¸ íŒŒì¼ë“¤
â”‚   â””â”€â”€ mao_pro/
â”‚       â””â”€â”€ runtime/
â”‚           â”œâ”€â”€ mao_pro.model3.json  # ëª¨ë¸ ë©”íƒ€ë°ì´í„°
â”‚           â”œâ”€â”€ mao_pro.moc3         # ëª¨ë¸ ë°”ì´ë„ˆë¦¬
â”‚           â”œâ”€â”€ expressions/         # í‘œì • íŒŒì¼ë“¤
â”‚           â””â”€â”€ motions/             # ëª¨ì…˜ íŒŒì¼ë“¤
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ libs/
â”‚       â”œâ”€â”€ live2d.min.js       # Live2D JavaScript SDK
â”‚       â””â”€â”€ live2dcubismcore.js # Live2D ì½”ì–´ ì—”ì§„
â”œâ”€â”€ model_dict.json             # ëª¨ë¸ ì„¤ì • ì‚¬ì „
â””â”€â”€ prompts/utils/
    â””â”€â”€ live2d_expression_prompt.txt  # í‘œì • í”„ë¡¬í”„íŠ¸
```

## ğŸ­ Live2D ëª¨ë¸ ê´€ë¦¬ ì‹œìŠ¤í…œ

### 1. Live2dModel í´ë˜ìŠ¤ (`live2d_model.py`)

**í•µì‹¬ ì—­í• **: Live2D ëª¨ë¸ì˜ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ ë° ê°ì • ë§¤í•‘ ì²˜ë¦¬

```python
class Live2dModel:
    """Live2D ëª¨ë¸ ì •ë³´ë¥¼ ê´€ë¦¬í•˜ëŠ” í•µì‹¬ í´ë˜ìŠ¤"""
    
    def __init__(self, live2d_model_name: str, model_dict_path: str = "model_dict.json"):
        self.model_dict_path: str = model_dict_path
        self.live2d_model_name: str = live2d_model_name
        self.set_model(live2d_model_name)
```

**ì£¼ìš” ê¸°ëŠ¥**:

#### A. ëª¨ë¸ ì •ë³´ ë¡œë”©
```python
def _lookup_model_info(self, model_name: str) -> dict:
    """ëª¨ë¸ ë”•ì…”ë„ˆë¦¬ì—ì„œ ëª¨ë¸ ì •ë³´ë¥¼ ì¡°íšŒ"""
    # model_dict.jsonì—ì„œ ëª¨ë¸ ì •ë³´ ë¡œë“œ
    # ëª¨ë¸ëª…ìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ ë§¤ì¹­ë˜ëŠ” ëª¨ë¸ ì •ë³´ ë°˜í™˜
```

#### B. ê°ì • ë§¤í•‘ ì‹œìŠ¤í…œ
```python
# model_dict.jsonì˜ ê°ì • ë§¤í•‘ ì˜ˆì‹œ
"emotionMap": {
    "neutral": 0,    # ì¤‘ë¦½ â†’ í‘œì • ì¸ë±ìŠ¤ 0
    "anger": 2,      # ë¶„ë…¸ â†’ í‘œì • ì¸ë±ìŠ¤ 2  
    "disgust": 2,    # í˜ì˜¤ â†’ í‘œì • ì¸ë±ìŠ¤ 2
    "fear": 1,       # ë‘ë ¤ì›€ â†’ í‘œì • ì¸ë±ìŠ¤ 1
    "joy": 3,        # ê¸°ì¨ â†’ í‘œì • ì¸ë±ìŠ¤ 3
    "smirk": 3,      # íë­‡í•¨ â†’ í‘œì • ì¸ë±ìŠ¤ 3
    "sadness": 1,    # ìŠ¬í”” â†’ í‘œì • ì¸ë±ìŠ¤ 1  
    "surprise": 3    # ë†€ëŒ â†’ í‘œì • ì¸ë±ìŠ¤ 3
}
```

#### C. í…ìŠ¤íŠ¸ì—ì„œ ê°ì • ì¶”ì¶œ
```python
def extract_emotion(self, str_to_check: str) -> list:
    """í…ìŠ¤íŠ¸ì—ì„œ [joy], [anger] ê°™ì€ ê°ì • íƒœê·¸ë¥¼ ì°¾ì•„ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    expression_list = []
    # "[joy]" â†’ 3, "[anger]" â†’ 2 ë³€í™˜
    return expression_list
```

#### D. ê°ì • í‚¤ì›Œë“œ ì œê±°
```python
def remove_emotion_keywords(self, target_str: str) -> str:
    """í…ìŠ¤íŠ¸ì—ì„œ [ê°ì •] íƒœê·¸ë¥¼ ì œê±°í•˜ê³  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜"""
    # "ì•ˆë…•í•˜ì„¸ìš”! [joy] ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”!" â†’ "ì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”!"
```

## ğŸŒ WebSocket í†µì‹  ì‹œìŠ¤í…œ

### 1. WebSocket Handler (`websocket_handler.py`)

**ì—­í• **: ì‹¤ì‹œê°„ í´ë¼ì´ì–¸íŠ¸-ì„œë²„ í†µì‹  ê´€ë¦¬

#### A. ì—°ê²° ê´€ë¦¬
```python
class WebSocketHandler:
    def __init__(self, default_context_cache: ServiceContext):
        self.client_connections: Dict[str, WebSocket] = {}
        self.client_contexts: Dict[str, ServiceContext] = {}
        self.chat_group_manager = ChatGroupManager()
```

#### B. ë©”ì‹œì§€ íƒ€ì… ë¶„ë¥˜
```python
class MessageType(Enum):
    GROUP = ["add-client-to-group", "remove-client-from-group"]
    HISTORY = ["fetch-history-list", "create-new-history"]  
    CONVERSATION = ["mic-audio-end", "text-input", "ai-speak-signal"]
    CONFIG = ["fetch-configs", "switch-config"]
    CONTROL = ["interrupt-signal", "audio-play-start"]
    DATA = ["mic-audio-data"]
```

#### C. í•µì‹¬ ë©”ì‹œì§€ ì²˜ë¦¬ íë¦„

```python
async def handle_websocket_communication(self, websocket: WebSocket, client_uid: str):
    """WebSocket ë©”ì‹œì§€ ìˆ˜ì‹  ë° ë¼ìš°íŒ…"""
    while True:
        message = await websocket.receive_text()
        data = json.loads(message)
        
        # ë©”ì‹œì§€ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬ê¸° í˜¸ì¶œ
        handler = self._message_handlers.get(data["type"])
        if handler:
            await handler(websocket, client_uid, data)
```

### 2. ì‹¤ì‹œê°„ Live2D ì—…ë°ì´íŠ¸ ë©”ì»¤ë‹ˆì¦˜

#### A. ê°ì • ìƒíƒœ ì „ì†¡
```python
# í´ë¼ì´ì–¸íŠ¸ë¡œ Live2D í‘œì • ë³€ê²½ ì‹ í˜¸ ì „ì†¡
await websocket.send_text(json.dumps({
    "type": "live2d_expression_update",
    "expression_index": 3,  # joy í‘œì •
    "duration": 2000       # 2ì´ˆê°„ ìœ ì§€
}))
```

#### B. ëª¨ì…˜ íŠ¸ë¦¬ê±°
```python  
# Live2D ëª¨ì…˜ ì‹¤í–‰ ì‹ í˜¸
await websocket.send_text(json.dumps({
    "type": "live2d_motion_trigger", 
    "motion_group": "Idle",
    "motion_index": 0
}))
```

## ğŸ¨ Live2D ëª¨ë¸ íŒŒì¼ êµ¬ì¡°

### 1. ëª¨ë¸ ë©”íƒ€ë°ì´í„° (`mao_pro.model3.json`)

```json
{
    "Version": 3,
    "FileReferences": {
        "Moc": "mao_pro.moc3",           // ëª¨ë¸ ë°”ì´ë„ˆë¦¬ íŒŒì¼
        "Textures": ["mao_pro.4096/texture_00.png"],  // í…ìŠ¤ì²˜ íŒŒì¼ë“¤
        "Physics": "mao_pro.physics3.json",     // ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        "Pose": "mao_pro.pose3.json",          // í¬ì¦ˆ ì„¤ì •
        "Expressions": [                        // í‘œì • íŒŒì¼ë“¤
            {"Name": "exp_01", "File": "expressions/exp_01.exp3.json"},
            {"Name": "exp_02", "File": "expressions/exp_02.exp3.json"}
        ],
        "Motions": {                           // ëª¨ì…˜ ê·¸ë£¹ë“¤
            "Idle": [{"File": "motions/mtn_01.motion3.json"}],
            "": [{"File": "motions/mtn_02.motion3.json"}]
        }
    },
    "Groups": [                               // íŒŒë¼ë¯¸í„° ê·¸ë£¹
        {
            "Target": "Parameter",
            "Name": "EyeBlink", 
            "Ids": ["ParamEyeLOpen", "ParamEyeROpen"]
        },
        {
            "Target": "Parameter", 
            "Name": "LipSync",
            "Ids": ["ParamA"]
        }
    ],
    "HitAreas": [                            // í´ë¦­ ê°€ëŠ¥ ì˜ì—­
        {"Id": "HitAreaHead", "Name": ""},
        {"Id": "HitAreaBody", "Name": ""}
    ]
}
```

### 2. í‘œì • ì‹œìŠ¤í…œ

- **í‘œì • íŒŒì¼**: `expressions/exp_01.exp3.json` ~ `exp_08.exp3.json`
- **ë§¤í•‘**: `model_dict.json`ì˜ emotionMapìœ¼ë¡œ ê°ì •â†’í‘œì •ì¸ë±ìŠ¤ ì—°ê²°
- **ì‚¬ìš©ë²•**: `[joy]` íƒœê·¸ â†’ ì¸ë±ìŠ¤ 3 â†’ `exp_04.exp3.json` ì‹¤í–‰

### 3. ëª¨ì…˜ ì‹œìŠ¤í…œ  

- **Idle ëª¨ì…˜**: ê¸°ë³¸ ëŒ€ê¸° ìƒíƒœ ëª¨ì…˜
- **ì¸í„°ë™í‹°ë¸Œ ëª¨ì…˜**: ì‚¬ìš©ì í´ë¦­ ì‹œ ì‹¤í–‰ë˜ëŠ” íŠ¹ìˆ˜ ëª¨ì…˜
- **HitArea**: í´ë¦­ ê°€ëŠ¥í•œ ì˜ì—­ ì •ì˜ (ë¨¸ë¦¬, ëª¸)

## ğŸ”„ ìºë¦­í„° ì‹¤í–‰ ì›Œí¬í”Œë¡œìš°

### 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë‹¨ê³„

```python
# 1. ì„œë²„ ì‹œì‘ ì‹œ
app = FastAPI(title="Open-LLM-VTuber Server")

# 2. ì„œë¹„ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
default_context_cache = ServiceContext()
await default_context_cache.initialize(config)

# 3. Live2D ëª¨ë¸ ë¡œë“œ
live2d_model = Live2dModel("mao_pro", "model_dict.json")

# 4. WebSocket í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
ws_handler = WebSocketHandler(default_context_cache)
```

### 2. í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ë‹¨ê³„

```python
@router.websocket("/client-ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    client_uid = str(uuid4())
    
    # ìƒˆ ì—°ê²° ì²˜ë¦¬
    await ws_handler.handle_new_connection(websocket, client_uid)
    
    # í†µì‹  ë£¨í”„ ì‹œì‘
    await ws_handler.handle_websocket_communication(websocket, client_uid)
```

### 3. ëŒ€í™” ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°

#### A. ì‚¬ìš©ì ì…ë ¥ â†’ AI ì‘ë‹µ â†’ Live2D ë°˜ì˜

```python
# 1. ì‚¬ìš©ì í…ìŠ¤íŠ¸ ì…ë ¥ ìˆ˜ì‹ 
{
    "type": "text-input",
    "text": "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì¢‹ì•„ìš”."
}

# 2. AI ì—ì´ì „íŠ¸ê°€ ì‘ë‹µ ìƒì„± (ê°ì • íƒœê·¸ í¬í•¨)
ai_response = "ì•ˆë…•í•˜ì„¸ìš”! [joy] ì €ë„ ê¸°ë¶„ì´ ì¢‹ë„¤ìš”! [surprise]"

# 3. Live2D ëª¨ë¸ì—ì„œ ê°ì • ì¶”ì¶œ
emotions = live2d_model.extract_emotion(ai_response)  # [3, 3]
clean_text = live2d_model.remove_emotion_keywords(ai_response)

# 4. í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
await websocket.send_text(json.dumps({
    "type": "ai-response",
    "text": clean_text,
    "expressions": emotions,
    "audio_data": tts_audio
}))
```

#### B. ìŒì„± ì…ë ¥ ì²˜ë¦¬

```python  
# 1. ìŒì„± ë°ì´í„° ìˆ˜ì‹ 
{
    "type": "mic-audio-data", 
    "audio": [0.1, 0.2, -0.1, ...]  # ì˜¤ë””ì˜¤ ë°°ì—´
}

# 2. ASRë¡œ ìŒì„±â†’í…ìŠ¤íŠ¸ ë³€í™˜
text = await asr.transcribe(audio_data)

# 3. ìœ„ì˜ í…ìŠ¤íŠ¸ ì…ë ¥ ì›Œí¬í”Œë¡œìš°ì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
```

### 4. Live2D í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™

#### A. JavaScript SDK ì‚¬ìš©

```javascript
// Live2D ëª¨ë¸ ë¡œë“œ
const model = await Live2DModel.loadModel("/live2d-models/mao_pro/runtime/mao_pro.model3.json");

// WebSocketìœ¼ë¡œ í‘œì • ì—…ë°ì´íŠ¸ ìˆ˜ì‹ 
websocket.onmessage = (event) => {
    const data = JSON.parse(event.data);
    
    if (data.type === "ai-response") {
        // í‘œì • ë³€ê²½
        data.expressions.forEach(expIndex => {
            model.setExpression(expIndex);
        });
        
        // TTS ì¬ìƒê³¼ ë¦½ì‹±í¬
        playAudioWithLipSync(data.audio_data);
    }
};
```

## âš™ï¸ ì„¤ì • ì‹œìŠ¤í…œ

### 1. ëª¨ë¸ ì„¤ì • (`model_dict.json`)

```json
[
    {
        "name": "mao_pro",                    // ëª¨ë¸ ì´ë¦„
        "description": "",                    // ì„¤ëª…
        "url": "/live2d-models/mao_pro/runtime/mao_pro.model3.json",  // ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        "kScale": 0.5,                       // í¬ê¸° ìŠ¤ì¼€ì¼
        "initialXshift": 0,                  // ì´ˆê¸° X ìœ„ì¹˜
        "initialYshift": 0,                  // ì´ˆê¸° Y ìœ„ì¹˜  
        "kXOffset": 1150,                    // X ì˜¤í”„ì…‹
        "idleMotionGroupName": "Idle",       // ê¸°ë³¸ ëª¨ì…˜ ê·¸ë£¹
        "emotionMap": { /* ê°ì • ë§¤í•‘ */ },   // ê°ì •â†’í‘œì •ì¸ë±ìŠ¤ ë§¤í•‘
        "tapMotions": { /* í´ë¦­ ëª¨ì…˜ */ }    // í´ë¦­ ì‹œ ì‹¤í–‰ë  ëª¨ì…˜
    }
]
```

### 2. í‘œì • í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ

```text
# prompts/utils/live2d_expression_prompt.txt

## Expressions
In your response, use the keywords provided below to express facial expressions:

- [neutral], [anger], [fear], [joy], [sadness], [surprise]

## Examples  
"Hi! [joy] Nice to meet you!"
"[surprise] That's a great question! [joy] Let me explain..."
```

**í”„ë¡¬í”„íŠ¸ ë™ì‘ ë°©ì‹**:
1. AI ì—ì´ì „íŠ¸ê°€ ì‘ë‹µ ìƒì„± ì‹œ ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì°¸ì¡°
2. `[ê°ì •]` íƒœê·¸ë¥¼ ì‘ë‹µì— ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
3. Live2D ì‹œìŠ¤í…œì´ íƒœê·¸ë¥¼ ê°ì§€í•˜ê³  í•´ë‹¹ í‘œì • ì‹¤í–‰

## ğŸ”§ êµ¬í˜„ ì‹œ í•µì‹¬ ê³ ë ¤ì‚¬í•­

### 1. Fortune VTuber í”„ë¡œì íŠ¸ ì ìš© ë°©ì•ˆ

#### A. ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í†µí•©
```python
# Fortune VTuberì˜ ê¸°ì¡´ Live2D ì„œë¹„ìŠ¤ì™€ ì—°ë™
from .services.live2d_service import Live2DService
from .live2d.emotion_bridge import emotion_bridge

# Open-LLM-VTuberì˜ ëª¨ë¸ ê´€ë¦¬ ê¸°ëŠ¥ ì ìš©
class FortuneLive2DModel(Live2dModel):
    """Fortune VTuberìš© Live2D ëª¨ë¸ í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str):
        super().__init__(model_name, "static/live2d/model_dict.json")
        
    def integrate_with_fortune_system(self):
        """ê¸°ì¡´ Fortune ì‹œìŠ¤í…œê³¼ í†µí•©"""
        # ê°ì • ë§¤í•‘ì„ ê¸°ì¡´ emotion_bridgeì™€ ì—°ë™
        # WebSocketì„ ê¸°ì¡´ live2d_websocketê³¼ í†µí•©
```

#### B. ê°ì • ì²˜ë¦¬ ì‹œìŠ¤í…œ í–¥ìƒ
```python
# Open-LLM-VTuberì˜ ê°ì • ì¶”ì¶œ ë¡œì§ì„ Fortune ì‹œìŠ¤í…œì— ì ìš©
def enhance_emotion_processing(fortune_result: dict, user_message: str) -> dict:
    """ìš´ì„¸ ê²°ê³¼ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ê°ì • ì¶”ì¶œ ë° Live2D ë°˜ì˜"""
    
    # 1. ê¸°ì¡´ ìš´ì„¸ ê¸°ë°˜ ê°ì • ê³„ì‚°
    emotion_data = emotion_bridge.calculate_emotion(fortune_result, session_id, user_uuid)
    
    # 2. Open-LLM-VTuber ë°©ì‹ì˜ í…ìŠ¤íŠ¸ ê°ì • íƒœê·¸ ì¶”ì¶œ  
    live2d_model = FortuneLife2DModel("mao_pro")
    extracted_emotions = live2d_model.extract_emotion(user_message)
    
    # 3. ë‘ ë°©ì‹ì„ ì¡°í•©í•˜ì—¬ ë” ì •í™•í•œ ê°ì • ìƒíƒœ ìƒì„±
    combined_emotion = combine_emotion_sources(emotion_data, extracted_emotions)
    
    return combined_emotion
```

### 2. ì„±ëŠ¥ ìµœì í™” ë°©ì•ˆ

#### A. ëª¨ë¸ íŒŒì¼ ìºì‹±
```python
class OptimizedLive2DModel:
    _model_cache = {}  # ëª¨ë¸ ì •ë³´ ìºì‹œ
    
    @classmethod
    def get_cached_model(cls, model_name: str):
        if model_name not in cls._model_cache:
            cls._model_cache[model_name] = Live2dModel(model_name)
        return cls._model_cache[model_name]
```

#### B. WebSocket ë©”ì‹œì§€ ë°°ì¹˜ ì²˜ë¦¬
```python
# ì—¬ëŸ¬ Live2D ì—…ë°ì´íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë©”ì‹œì§€ë¡œ ë°°ì¹˜ ì „ì†¡
async def send_batch_live2d_updates(websocket: WebSocket, updates: list):
    batch_message = {
        "type": "live2d_batch_update",
        "updates": updates,
        "timestamp": time.time()
    }
    await websocket.send_text(json.dumps(batch_message))
```

### 3. í™•ì¥ì„± ê³ ë ¤ì‚¬í•­

#### A. ë‹¤ì¤‘ ìºë¦­í„° ì§€ì›
```python
class MultiCharacterManager:
    def __init__(self):
        self.characters = {}
        
    def load_character(self, char_name: str, model_path: str):
        self.characters[char_name] = Live2dModel(char_name, model_path)
        
    def switch_character(self, websocket: WebSocket, char_name: str):
        # ìºë¦­í„° ì „í™˜ ë¡œì§
```

#### B. ì»¤ìŠ¤í…€ í‘œì •/ëª¨ì…˜ ì‹œìŠ¤í…œ
```python
class CustomExpressionManager:
    def create_custom_emotion_map(self, base_map: dict, custom_emotions: dict):
        """ì‚¬ìš©ì ì •ì˜ ê°ì • ë§¤í•‘ ìƒì„±"""
        return {**base_map, **custom_emotions}
        
    def register_custom_motion(self, motion_name: str, motion_file: str):
        """ì‚¬ìš©ì ì •ì˜ ëª¨ì…˜ ë“±ë¡"""
```

## ğŸ“Š ì‹œìŠ¤í…œ íë¦„ë„

```
[ì‚¬ìš©ì ì…ë ¥] 
    â†“
[WebSocket ìˆ˜ì‹ ]
    â†“  
[ë©”ì‹œì§€ íƒ€ì… ë¶„ë¥˜]
    â†“
[AI ì—ì´ì „íŠ¸ ì²˜ë¦¬]
    â†“
[ì‘ë‹µ í…ìŠ¤íŠ¸ ìƒì„±] (ê°ì • íƒœê·¸ í¬í•¨)
    â†“
[Live2D ëª¨ë¸ì—ì„œ ê°ì • ì¶”ì¶œ]
    â†“
[ê°ì • íƒœê·¸ ì œê±° + ìˆœìˆ˜ í…ìŠ¤íŠ¸ ë¶„ë¦¬]
    â†“
[TTS ìŒì„± ìƒì„±]
    â†“
[WebSocketìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡]
    â†“
[í”„ë¡ íŠ¸ì—”ë“œì—ì„œ Live2D í‘œì •/ëª¨ì…˜ ì‹¤í–‰]
    â†“
[ìŒì„± ì¬ìƒ + ë¦½ì‹±í¬]
```

## ğŸ¯ Fortune VTuber êµ¬í˜„ ê¶Œì¥ì‚¬í•­

### 1. ë‹¨ê³„ë³„ êµ¬í˜„ ì ‘ê·¼ë²•

**Phase 1**: ê¸°ë³¸ ê°ì • ë§¤í•‘ í†µí•©
- Open-LLM-VTuberì˜ `Live2dModel` í´ë˜ìŠ¤ ì ìš©
- ê¸°ì¡´ `emotion_bridge.py`ì™€ ì—°ë™
- í…ìŠ¤íŠ¸ ê°ì • íƒœê·¸ ì¶”ì¶œ ê¸°ëŠ¥ ì¶”ê°€

**Phase 2**: WebSocket ë©”ì‹œì§€ í™•ì¥  
- Live2D ì „ìš© ë©”ì‹œì§€ íƒ€ì… ì¶”ê°€
- ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ êµ¬í˜„
- ì‹¤ì‹œê°„ í‘œì • ë™ê¸°í™” ìµœì í™”

**Phase 3**: ê³ ë„í™” ê¸°ëŠ¥
- ë‹¤ì¤‘ ìºë¦­í„° ì§€ì›
- ì»¤ìŠ¤í…€ í‘œì •/ëª¨ì…˜ ì‹œìŠ¤í…œ
- ì‚¬ìš©ìë³„ ìºë¦­í„° ì„¤ì • ì €ì¥

### 2. ì½”ë“œ ì¬ì‚¬ìš© ê°€ì´ë“œ

**ì§ì ‘ ì ìš© ê°€ëŠ¥í•œ ì½”ë“œ**:
- `Live2dModel` í´ë˜ìŠ¤ì˜ ê°ì • ë§¤í•‘ ë¡œì§
- í…ìŠ¤íŠ¸ ê°ì • íƒœê·¸ ì¶”ì¶œ/ì œê±° í•¨ìˆ˜
- ëª¨ë¸ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡° ë° ë¡œë”© ì‹œìŠ¤í…œ

**ìˆ˜ì • í›„ ì ìš© ê¶Œì¥**:  
- WebSocket í•¸ë“¤ëŸ¬ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í†µí•© í•„ìš”)
- ì„œë²„ ì„¤ì • ë¶€ë¶„ (FastAPI ì„¤ì • ì°¨ì´)
- í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ ë¶€ë¶„ (React êµ¬ì¡° ì°¨ì´)

ì´ ë¶„ì„ ë³´ê³ ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ Fortune VTuber í”„ë¡œì íŠ¸ì˜ Live2D ê¸°ëŠ¥ì„ ì²´ê³„ì ìœ¼ë¡œ ê°œì„ í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.