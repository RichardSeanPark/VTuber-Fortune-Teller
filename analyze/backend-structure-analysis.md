# Backend Structure Analysis

## 1. ì„œë²„ ì•„í‚¤í…ì²˜ ê°œìš”

### í”„ë¡œì íŠ¸ êµ¬ì¡° ë° ë””ë ‰í† ë¦¬ êµ¬ì„±
```
src/open_llm_vtuber/
â”œâ”€â”€ server.py                    # ë©”ì¸ ì›¹ì†Œì¼“ ì„œë²„
â”œâ”€â”€ routes.py                    # API ë¼ìš°íŒ… ë° ì—”ë“œí¬ì¸íŠ¸
â”œâ”€â”€ websocket_handler.py         # ì›¹ì†Œì¼“ ì—°ê²° ê´€ë¦¬
â”œâ”€â”€ service_context.py           # ì„œë¹„ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
â”œâ”€â”€ config_manager/              # ì„¤ì • ê´€ë¦¬ ëª¨ë“ˆ
â”œâ”€â”€ agent/                       # AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
â”œâ”€â”€ asr/                         # ìŒì„± ì¸ì‹ ì—”ì§„
â”œâ”€â”€ tts/                         # ìŒì„± í•©ì„± ì—”ì§„
â”œâ”€â”€ vad/                         # ìŒì„± í™œë™ ê°ì§€
â”œâ”€â”€ mcpp/                        # MCP(Model Context Protocol) ë„êµ¬
â”œâ”€â”€ conversations/               # ëŒ€í™” ì²˜ë¦¬ ë¡œì§
â”œâ”€â”€ live2d_model.py             # Live2D ëª¨ë¸ ê´€ë¦¬
â”œâ”€â”€ chat_history_manager.py     # ì±„íŒ… ê¸°ë¡ ê´€ë¦¬
â””â”€â”€ utils/                      # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
```

### ì‚¬ìš©ëœ í”„ë ˆì„ì›Œí¬ ë° ê¸°ìˆ  ìŠ¤íƒ

**í•µì‹¬ í”„ë ˆì„ì›Œí¬:**
- **FastAPI**: ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ì›¹ í”„ë ˆì„ì›Œí¬
- **WebSocket**: ì‹¤ì‹œê°„ ì–‘ë°©í–¥ í†µì‹ 
- **Uvicorn**: ASGI ì„œë²„
- **Pydantic**: ë°ì´í„° ê²€ì¦ ë° ì„¤ì • ê´€ë¦¬

**AI/ML ë¼ì´ë¸ŒëŸ¬ë¦¬:**
- **Anthropic**: Claude API ì—°ë™
- **OpenAI**: GPT ëª¨ë¸ ì—°ë™
- **Sherpa-ONNX**: ì˜¤í”„ë¼ì¸ ASR/TTS
- **Faster-Whisper**: ìŒì„± ì¸ì‹
- **Edge-TTS**: ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ìŒì„± í•©ì„±

**ê¸°íƒ€ ì˜ì¡´ì„±:**
- **Loguru**: êµ¬ì¡°í™”ëœ ë¡œê¹…
- **NumPy**: ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬
- **PyYAML**: ì„¤ì • íŒŒì¼ ê´€ë¦¬
- **WebSocket-Client**: ì›¹ì†Œì¼“ í´ë¼ì´ì–¸íŠ¸

### ì„œë²„ ì„¤ì • ë° ë¯¸ë“¤ì›¨ì–´ êµ¬ì„±

**CORS ë¯¸ë“¤ì›¨ì–´:**
```python
# ëª¨ë“  ë„ë©”ì¸ì—ì„œ ì ‘ê·¼ í—ˆìš©
CORSMiddleware(
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)
```

**ì •ì  íŒŒì¼ ì„œë¹™:**
- `/cache`: ì˜¤ë””ì˜¤ ìºì‹œ íŒŒì¼
- `/live2d-models`: Live2D ëª¨ë¸ íŒŒì¼
- `/bg`: ë°°ê²½ ì´ë¯¸ì§€
- `/avatars`: ì•„ë°”íƒ€ ì´ë¯¸ì§€ (ë³´ì•ˆ í•„í„°ë§ ì ìš©)
- `/web-tool`: ì›¹ ë„êµ¬
- `/`: í”„ë¡ íŠ¸ì—”ë“œ (catch-all)

## 2. API êµ¬ì¡° ë° ì—”ë“œí¬ì¸íŠ¸

### RESTful API ì„¤ê³„ íŒ¨í„´

**ì£¼ìš” ì—”ë“œí¬ì¸íŠ¸:**

```python
# WebSocket ì—°ê²°
@router.websocket("/client-ws")
async def websocket_endpoint(websocket: WebSocket)

# TTS WebSocket
@router.websocket("/tts-ws") 
async def tts_endpoint(websocket: WebSocket)

# í”„ë¡ì‹œ WebSocket (ì„ íƒì )
@router.websocket("/proxy-ws")
async def proxy_endpoint(websocket: WebSocket)

# ASR ìŒì„± ì¸ì‹
@router.post("/asr")
async def transcribe_audio(file: UploadFile = File(...))

# Live2D ëª¨ë¸ ì •ë³´
@router.get("/live2d-models/info")
async def get_live2d_folder_info()

# ì›¹ ë„êµ¬ ë¦¬ë‹¤ì´ë ‰íŠ¸
@router.get("/web-tool")
async def web_tool_redirect()
```

### ë¼ìš°íŒ… êµ¬ì¡°

**ë¼ìš°í„° íŒ©í† ë¦¬ íŒ¨í„´:**
```python
def init_client_ws_route(default_context_cache: ServiceContext) -> APIRouter
def init_proxy_route(server_url: str) -> APIRouter  
def init_webtool_routes(default_context_cache: ServiceContext) -> APIRouter
```

### ìš”ì²­/ì‘ë‹µ ë°ì´í„° í˜•ì‹

**WebSocket ë©”ì‹œì§€ íƒ€ì…:**
```python
class WSMessage(TypedDict, total=False):
    type: str                    # ë©”ì‹œì§€ íƒ€ì…
    action: Optional[str]        # ì•¡ì…˜
    text: Optional[str]          # í…ìŠ¤íŠ¸ ë‚´ìš©
    audio: Optional[List[float]] # ì˜¤ë””ì˜¤ ë°ì´í„°
    images: Optional[List[str]]  # ì´ë¯¸ì§€ ë°ì´í„°
    history_uid: Optional[str]   # íˆìŠ¤í† ë¦¬ ID
```

**ì£¼ìš” ë©”ì‹œì§€ íƒ€ì…:**
- `mic-audio-data`: ë§ˆì´í¬ ì˜¤ë””ì˜¤ ë°ì´í„°
- `text-input`: í…ìŠ¤íŠ¸ ì…ë ¥
- `interrupt-signal`: ëŒ€í™” ì¤‘ë‹¨
- `fetch-history-list`: íˆìŠ¤í† ë¦¬ ëª©ë¡ ìš”ì²­
- `switch-config`: ì„¤ì • ë³€ê²½

## 3. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„

### ë°ì´í„° ëª¨ë¸ êµ¬ì¡°

**íŒŒì¼ ê¸°ë°˜ ì €ì¥ì†Œ (JSON):**
```python
class HistoryMessage(TypedDict):
    role: Literal["human", "ai"]     # ë°œí™”ì ì—­í• 
    timestamp: str                   # íƒ€ì„ìŠ¤íƒ¬í”„
    content: str                     # ë©”ì‹œì§€ ë‚´ìš©
    name: Optional[str]              # í‘œì‹œ ì´ë¦„
    avatar: Optional[str]            # ì•„ë°”íƒ€ URL
```

**ë””ë ‰í† ë¦¬ êµ¬ì¡°:**
```
chat_history/
â”œâ”€â”€ {conf_uid}/                 # ì„¤ì •ë³„ ë””ë ‰í† ë¦¬
â”‚   â”œâ”€â”€ {history_uid}.json     # ê°œë³„ ëŒ€í™” ê¸°ë¡
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

### ìŠ¤í‚¤ë§ˆ ì •ì˜

**Live2D ëª¨ë¸ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "name": "model_name",
  "url": "model_path.model3.json",
  "emotionMap": {
    "neutral": 0,
    "joy": 1,
    "anger": 2,
    "sadness": 3,
    "surprise": 4
  }
}
```

**ì„¤ì • íŒŒì¼ ìŠ¤í‚¤ë§ˆ (YAML):**
```yaml
system_config:
  host: "localhost"
  port: 12393
  config_alts_dir: "characters"

character_config:
  conf_name: "character_name"
  conf_uid: "unique_id" 
  live2d_model_name: "model_name"
  persona_prompt: "AI personality description"
```

### ê´€ê³„ ì„¤ì • ë° ì¸ë±ì‹±

**íŒŒì¼ ê¸°ë°˜ ê´€ê³„:**
- `conf_uid` â†’ ì„¤ì •ë³„ ëŒ€í™” ê¸°ë¡ ê·¸ë£¹í™”
- `history_uid` â†’ ê°œë³„ ëŒ€í™” ì„¸ì…˜ ì‹ë³„
- `live2d_model_name` â†’ model_dict.jsonì˜ ëª¨ë¸ ì •ë³´ ë§¤í•‘

**ì•ˆì „ì„± ë° ê²€ì¦:**
```python
def _sanitize_path_component(component: str) -> str:
    """ê²½ë¡œ ì»´í¬ë„ŒíŠ¸ ì•ˆì „ì„± ê²€ì¦"""
    sanitized = os.path.basename(component.strip())
    if not _is_safe_filename(sanitized):
        raise ValueError(f"Invalid characters: {component}")
    return sanitized
```

## 4. ì¸ì¦ ë° ë³´ì•ˆ

### ì‚¬ìš©ì ì¸ì¦ ì‹œìŠ¤í…œ

**í´ë¼ì´ì–¸íŠ¸ ì‹ë³„:**
```python
# UUID ê¸°ë°˜ í´ë¼ì´ì–¸íŠ¸ ì‹ë³„
client_uid = str(uuid4())
```

**ì„¸ì…˜ ê¸°ë°˜ ì¸ì¦:**
- WebSocket ì—°ê²°ì‹œ ê³ ìœ  UUID í• ë‹¹
- ë©”ëª¨ë¦¬ ê¸°ë°˜ ì„¸ì…˜ ê´€ë¦¬
- ì—°ê²° í•´ì œì‹œ ìë™ ì •ë¦¬

### ì„¸ì…˜/í† í° ê´€ë¦¬

**ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸:**
```python
class ServiceContext:
    def __init__(self):
        self.client_uid: str = None      # í´ë¼ì´ì–¸íŠ¸ ì‹ë³„ì
        self.history_uid: str = ""       # í˜„ì¬ ëŒ€í™” ì„¸ì…˜
        self.send_text: Callable = None  # ë©”ì‹œì§€ ì „ì†¡ í•¨ìˆ˜
```

**ë©”ëª¨ë¦¬ ê¸°ë°˜ ê´€ë¦¬:**
```python
self.client_connections: Dict[str, WebSocket] = {}
self.client_contexts: Dict[str, ServiceContext] = {}
self.received_data_buffers: Dict[str, np.ndarray] = {}
```

### ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´ ë° ì •ì±…

**íŒŒì¼ ì ‘ê·¼ ë³´ì•ˆ:**
```python
class AvatarStaticFiles(CORSStaticFiles):
    async def get_response(self, path: str, scope):
        allowed_extensions = (".jpg", ".jpeg", ".png", ".gif", ".svg")
        if not any(path.lower().endswith(ext) for ext in allowed_extensions):
            return Response("Forbidden file type", status_code=403)
```

**ê²½ë¡œ ìˆœíšŒ ê³µê²© ë°©ì§€:**
```python
def _get_safe_history_path(conf_uid: str, history_uid: str) -> str:
    base_dir = os.path.join("chat_history", safe_conf_uid)
    full_path = os.path.normpath(os.path.join(base_dir, f"{safe_history_uid}.json"))
    if not full_path.startswith(base_dir):
        raise ValueError("Path traversal detected")
```

## 5. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§

### ì„œë¹„ìŠ¤ ë ˆì´ì–´ êµ¬ì¡°

**íŒ©í† ë¦¬ íŒ¨í„´ ì ìš©:**
```python
class AgentFactory:
    @staticmethod
    def create_agent(conversation_agent_choice: str, **kwargs) -> AgentInterface

class TTSFactory:
    @staticmethod  
    def get_tts_engine(engine_type: str, **kwargs) -> TTSInterface

class ASRFactory:
    @staticmethod
    def get_asr_system(system_name: str, **kwargs) -> ASRInterface
```

### ë°ì´í„° ì²˜ë¦¬ ë¡œì§

**ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬:**
```python
# 16-bit PCM to float32 ë³€í™˜
audio_array = (
    np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
)

# ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë²„í¼ë§
self.received_data_buffers[client_uid] = np.append(
    self.received_data_buffers[client_uid],
    np.array(audio_data, dtype=np.float32)
)
```

**ë©”ì‹œì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:**
```python
@tts_filter(self._tts_preprocessor_config)
@display_processor()
@actions_extractor(self._live2d_model)  
@sentence_divider(faster_first_response=True)
async def chat_with_memory(input_data: BatchInput):
    # ë©”ì‹œì§€ ì²˜ë¦¬ ë¡œì§
```

### ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ êµ¬í˜„

**ëŒ€í™” ìƒíƒœ ê´€ë¦¬:**
```python
class GroupConversationState:
    current_speaker_uid: str = None
    conversation_history: List = []
    
    @staticmethod
    def get_state(group_id: str) -> 'GroupConversationState'
    
    @staticmethod  
    def remove_state(group_id: str) -> None
```

**ì¸í„°ëŸ½íŠ¸ ì²˜ë¦¬:**
```python
def handle_interrupt(self, heard_response: str) -> None:
    if self._memory and self._memory[-1]["role"] == "assistant":
        self._memory[-1]["content"] = heard_response + "..."
    
    interrupt_role = "system" if self.interrupt_method == "system" else "user"
    self._memory.append({
        "role": interrupt_role,
        "content": "[Interrupted by user]"
    })
```

## 6. ì™¸ë¶€ ì„œë¹„ìŠ¤ í†µí•©

### ì™¸ë¶€ API ì—°ë™ ë°©ì‹

**LLM API í†µí•©:**
```python
# Claude API ì—°ë™
class ClaudeAsyncLLM(StatelessLLMInterface):
    async def chat_completion(self, messages, system_prompt, **kwargs):
        # Anthropic API í˜¸ì¶œ

# OpenAI í˜¸í™˜ API ì—°ë™  
class OpenAICompatibleAsyncLLM(StatelessLLMInterface):
    async def chat_completion(self, messages, system_prompt, tools=None):
        # OpenAI í˜¸í™˜ API í˜¸ì¶œ
```

**ìŒì„± ì„œë¹„ìŠ¤ í†µí•©:**
```python
# Azure TTS ì—°ë™
class AzureTTSEngine(TTSInterface):
    async def async_generate_audio(self, text: str, file_name_no_ext: str):
        # Azure Cognitive Services í˜¸ì¶œ

# Edge TTS ì—°ë™ (ë¬´ë£Œ)
class EdgeTTSEngine(TTSInterface):
    async def async_generate_audio(self, text: str, file_name_no_ext: str):
        # Microsoft Edge TTS í˜¸ì¶œ
```

### ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©

**MCP (Model Context Protocol) í†µí•©:**
```python
class MCPClient:
    def __init__(self, server_registry: ServerRegistry, send_text, client_uid):
        self.server_registry = server_registry
        self.active_sessions = {}
        
    async def execute_tool(self, server_name: str, tool_name: str, arguments: dict):
        # MCP ì„œë²„ì™€ ë„êµ¬ ì‹¤í–‰
```

**Live2D í‘œì • ì œì–´:**
```python
class Live2dModel:
    def extract_emotion(self, str_to_check: str) -> list:
        expression_list = []
        for key in self.emo_map.keys():
            emo_tag = f"[{key}]"
            if emo_tag in str_to_check.lower():
                expression_list.append(self.emo_map[key])
        return expression_list
```

### ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„ ë¡œì§

**ê³„ì¸µì  ì—ëŸ¬ ì²˜ë¦¬:**
```python
try:
    # ì„œë¹„ìŠ¤ í˜¸ì¶œ
    result = await service.call()
except ServiceSpecificError as e:
    logger.error(f"Service error: {e}")
    # ì„œë¹„ìŠ¤ë³„ ë³µêµ¬ ë¡œì§
except Exception as e:
    logger.error(f"Unexpected error: {e}")
    # ì¼ë°˜ì ì¸ ì—ëŸ¬ ì²˜ë¦¬
finally:
    # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
```

**ì¬ì‹œë„ íŒ¨í„´:**
```python
# ì§€ìˆ˜ ë°±ì˜¤í”„ì™€ í•¨ê»˜ ì¬ì‹œë„
for attempt in range(max_retries):
    try:
        return await api_call()
    except RetryableError:
        if attempt < max_retries - 1:
            await asyncio.sleep(2 ** attempt)
        else:
            raise
```

## 7. ì„±ëŠ¥ ë° í™•ì¥ì„±

### ìºì‹± ì „ëµ

**ë©”ëª¨ë¦¬ ìºì‹±:**
```python
# ì„œë¹„ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ìºì‹±
self.default_context_cache = ServiceContext()

# ì˜¤ë””ì˜¤ ë²„í¼ ìºì‹±  
self.received_data_buffers: Dict[str, np.ndarray] = {}

# í´ë¼ì´ì–¸íŠ¸ ì»¨í…ìŠ¤íŠ¸ ìºì‹±
self.client_contexts: Dict[str, ServiceContext] = {}
```

**íŒŒì¼ ìºì‹±:**
```python
# ì˜¤ë””ì˜¤ íŒŒì¼ ìºì‹œ
cache_dir = "cache"
audio_path = f"cache/{file_name}.mp3"

# ì •ì  íŒŒì¼ ìºì‹± (ë¸Œë¼ìš°ì € ë ˆë²¨)
self.app.mount("/cache", CORSStaticFiles(directory="cache"))
```

### ë¡œë“œ ë°¸ëŸ°ì‹± ê³ ë ¤ì‚¬í•­

**ë¹„ë™ê¸° ì²˜ë¦¬:**
```python
# WebSocket ì—°ê²°ë³„ ë…ë¦½ì  ì²˜ë¦¬
async def handle_websocket_communication(self, websocket: WebSocket, client_uid: str):
    while True:
        data = await websocket.receive_json()
        await self._route_message(websocket, client_uid, data)
```

**ë¦¬ì†ŒìŠ¤ ê²©ë¦¬:**
```python
# í´ë¼ì´ì–¸íŠ¸ë³„ ì„œë¹„ìŠ¤ ì»¨í…ìŠ¤íŠ¸ ë¶„ë¦¬
session_service_context = ServiceContext()
await session_service_context.load_cache(
    config=self.default_context_cache.config.model_copy(deep=True)
)
```

### ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

**êµ¬ì¡°í™”ëœ ë¡œê¹…:**
```python
logger.add(
    "logs/debug_{time:YYYY-MM-DD}.log",
    rotation="10 MB",
    retention="30 days", 
    level="DEBUG",
    format="{time} | {level} | {name}:{function}:{line} | {message}"
)
```

**ì„±ëŠ¥ ë©”íŠ¸ë¦­:**
- WebSocket ì—°ê²° ìˆ˜ ì¶”ì 
- ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì§€ì—°ì‹œê°„ ì¸¡ì •
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- API ì‘ë‹µ ì‹œê°„ ì¸¡ì •

## 8. ë°°í¬ ë° DevOps

### ë¹Œë“œ ë° ë°°í¬ í”„ë¡œì„¸ìŠ¤

**Python íŒ¨í‚¤ì§€ ê´€ë¦¬:**
```toml
[project]
name = "open-llm-vtuber"
version = "1.2.0"
requires-python = ">=3.10,<3.13"
dependencies = [
    "fastapi[standard]>=0.115.8",
    "uvicorn[standard]>=0.33.0",
    "anthropic>=0.40.0",
    "openai>=1.57.4"
]
```

**Docker ì§€ì›:**
```dockerfile
# Dockerfile ê¸°ë°˜ ì»¨í…Œì´ë„ˆí™”
FROM python:3.11-slim
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "run_server.py"]
```

### í™˜ê²½ ì„¤ì • ê´€ë¦¬

**ê³„ì¸µì  ì„¤ì •:**
```python
# ê¸°ë³¸ ì„¤ì • + ëŒ€ì•ˆ ì„¤ì • ë³‘í•©
def deep_merge(dict1, dict2):
    result = dict1.copy()
    for key, value in dict2.items():
        if key in result and isinstance(result[key], dict):
            result[key] = deep_merge(result[key], value)
        else:
            result[key] = value
    return result
```

**í™˜ê²½ë³„ ì„¤ì •:**
```yaml
# ê°œë°œ í™˜ê²½
system_config:
  host: "localhost"
  port: 12393

# í”„ë¡œë•ì…˜ í™˜ê²½  
system_config:
  host: "0.0.0.0"
  port: 8080
```

### CI/CD íŒŒì´í”„ë¼ì¸

**ìë™í™”ëœ í…ŒìŠ¤íŠ¸:**
```python
# Pre-commit í›… ì„¤ì •
[tool.ruff]
target-version = "py310"

[tool.ruff.lint]
per-file-ignores = { "scripts/run_bilibili_live.py" = ["E402"] }
```

**ì˜ì¡´ì„± ê´€ë¦¬:**
```bash
# uvë¥¼ ì‚¬ìš©í•œ ì˜ì¡´ì„± ê´€ë¦¬
uv pip compile pyproject.toml -o requirements.txt
uv run run_server.py --verbose
```

## 9. í•µì‹¬ ê¸°ëŠ¥ë³„ êµ¬í˜„ ë¶„ì„

### Live2D ëª¨ë¸ ê´€ë¦¬

**ëª¨ë¸ ì •ë³´ ë¡œë”©:**
```python
class Live2dModel:
    def __init__(self, live2d_model_name: str):
        self.model_info = self._lookup_model_info(live2d_model_name)
        self.emo_map = {k.lower(): v for k, v in self.model_info["emotionMap"].items()}
        self.emo_str = " ".join([f"[{key}]," for key in self.emo_map.keys()])
```

**í‘œì • ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜:**
```python
def extract_emotion(self, str_to_check: str) -> list:
    expression_list = []
    str_to_check = str_to_check.lower()
    
    i = 0
    while i < len(str_to_check):
        if str_to_check[i] != "[":
            i += 1
            continue
        for key in self.emo_map.keys():
            emo_tag = f"[{key}]"
            if str_to_check[i:i + len(emo_tag)] == emo_tag:
                expression_list.append(self.emo_map[key])
                i += len(emo_tag) - 1
                break
        i += 1
    return expression_list
```

### ì‹¤ì‹œê°„ ìŒì„± ì²˜ë¦¬

**ìŒì„± ì¸ì‹ íŒŒì´í”„ë¼ì¸:**
```python
async def transcribe_audio(file: UploadFile = File(...)):
    contents = await file.read()
    wav_header_size = 44
    audio_data = contents[wav_header_size:]
    
    # 16-bit PCM to float32 ë³€í™˜
    audio_array = (
        np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
    )
    
    text = await default_context_cache.asr_engine.async_transcribe_np(audio_array)
    return {"text": text}
```

**ìŒì„± í•©ì„± ìŠ¤íŠ¸ë¦¬ë°:**
```python
@router.websocket("/tts-ws")
async def tts_endpoint(websocket: WebSocket):
    while True:
        data = await websocket.receive_json()
        text = data.get("text")
        
        # ë¬¸ì¥ ë¶„í• 
        sentences = [s.strip() for s in text.split(".") if s.strip()]
        
        for sentence in sentences:
            audio_path = await tts_engine.async_generate_audio(
                text=sentence, 
                file_name_no_ext=f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid4()[:8]}"
            )
            
            await websocket.send_json({
                "status": "partial",
                "audioPath": audio_path,
                "text": sentence
            })
```

### ëŒ€í™” ê´€ë¦¬ ì‹œìŠ¤í…œ

**ê°œë³„ ëŒ€í™” ì²˜ë¦¬:**
```python
async def process_single_conversation(
    context: ServiceContext,
    websocket_send: Callable,
    client_uid: str,
    user_input: Union[str, np.ndarray],
    images: List = None,
    session_emoji: str = "ğŸ­",
    metadata: dict = None
):
    # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
    input_data = BatchInput(
        texts=[TextData(content=user_input, source=TextSource.INPUT)],
        images=images or [],
        metadata=metadata
    )
    
    # AI ì—ì´ì „íŠ¸ì™€ ëŒ€í™”
    async for sentence_output in context.agent_engine.chat(input_data):
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        await websocket_send(json.dumps({
            "type": "sentence-partial" if sentence_output.sentence else "token",
            "text": sentence_output.text,
            "actions": sentence_output.actions
        }))
```

**ê·¸ë£¹ ëŒ€í™” ê´€ë¦¬:**
```python
class GroupConversationState:
    group_states: Dict[str, 'GroupConversationState'] = {}
    
    def __init__(self):
        self.current_speaker_uid: str = None
        self.conversation_history: List = []
        self.is_processing: bool = False
    
    @staticmethod
    def get_state(group_id: str) -> 'GroupConversationState':
        if group_id not in GroupConversationState.group_states:
            GroupConversationState.group_states[group_id] = GroupConversationState()
        return GroupConversationState.group_states[group_id]
```

### ë„êµ¬ í†µí•© ì‹œìŠ¤í…œ (MCP)

**ë„êµ¬ ê´€ë¦¬ì:**
```python
class ToolManager:
    def __init__(self, formatted_tools_openai: List[Dict], formatted_tools_claude: List[Dict]):
        self._formatted_tools_openai = formatted_tools_openai or []
        self._formatted_tools_claude = formatted_tools_claude or []
    
    def get_formatted_tools(self, mode: Literal["OpenAI", "Claude"]) -> List[Dict]:
        if mode == "OpenAI":
            return self._formatted_tools_openai
        elif mode == "Claude":
            return self._formatted_tools_claude
```

**ë„êµ¬ ì‹¤í–‰:**
```python
class ToolExecutor:
    async def execute_tools(self, tool_calls: List, caller_mode: str):
        for tool_call in tool_calls:
            try:
                result = await self.mcp_client.execute_tool(
                    server_name=tool_call.server_name,
                    tool_name=tool_call.name,
                    arguments=tool_call.arguments
                )
                yield {"type": "tool_result", "result": result}
            except Exception as e:
                yield {"type": "tool_error", "error": str(e)}
```

### ì„¤ì • ê´€ë¦¬

**ë™ì  ì„¤ì • ì „í™˜:**
```python
async def handle_config_switch(self, websocket: WebSocket, config_file_name: str):
    if config_file_name == "conf.yaml":
        new_config_data = read_yaml("conf.yaml").get("character_config")
    else:
        characters_dir = self.system_config.config_alts_dir
        file_path = os.path.join(characters_dir, config_file_name)
        alt_config_data = read_yaml(file_path).get("character_config")
        
        # ê¹Šì€ ë³‘í•©
        new_config_data = deep_merge(
            self.config.character_config.model_dump(), 
            alt_config_data
        )
    
    new_config = validate_config({
        "system_config": self.system_config.model_dump(),
        "character_config": new_config_data
    })
    
    await self.load_from_config(new_config)
```

## Live2D ê¸°ë°˜ ìš´ì„¸ ì•± ë°±ì—”ë“œ ê°œë°œì„ ìœ„í•œ í™œìš© ë°©ì•ˆ

### 1. ì•„í‚¤í…ì²˜ íŒ¨í„´ ì ìš©

**ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì§€í–¥ êµ¬ì¡°:**
```python
# ìš´ì„¸ ì„œë¹„ìŠ¤ ëª¨ë“ˆ
src/fortune_vtuber/
â”œâ”€â”€ fortune_service/          # ìš´ì„¸ ë¡œì§ ì„œë¹„ìŠ¤
â”œâ”€â”€ live2d_emotion/          # Live2D ê°ì • ì œì–´
â”œâ”€â”€ personality_engine/       # ì„±ê²© ê¸°ë°˜ ì‘ë‹µ
â”œâ”€â”€ daily_content/           # ì¼ì¼ ì»¨í…ì¸  ê´€ë¦¬
â””â”€â”€ user_profile/            # ì‚¬ìš©ì í”„ë¡œí•„ ê´€ë¦¬
```

**íŒ©í† ë¦¬ íŒ¨í„´ì„ í™œìš©í•œ ìš´ì„¸ ì—”ì§„:**
```python
class FortuneEngineFactory:
    @staticmethod
    def create_fortune_engine(fortune_type: str, **kwargs) -> FortuneInterface:
        if fortune_type == "tarot":
            return TarotFortuneEngine(**kwargs)
        elif fortune_type == "zodiac":
            return ZodiacFortuneEngine(**kwargs)
        elif fortune_type == "daily":
            return DailyFortuneEngine(**kwargs)
```

### 2. ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš© êµ¬í˜„

**ìš´ì„¸ ìƒë‹´ WebSocket:**
```python
@router.websocket("/fortune-ws")
async def fortune_consultation(websocket: WebSocket):
    await websocket.accept()
    client_uid = str(uuid4())
    
    try:
        while True:
            data = await websocket.receive_json()
            
            if data["type"] == "fortune-request":
                # ìš´ì„¸ ìš”ì²­ ì²˜ë¦¬
                fortune_result = await process_fortune_request(
                    request_type=data["fortune_type"],
                    user_data=data["user_info"],
                    client_uid=client_uid
                )
                
                await websocket.send_json({
                    "type": "fortune-response",
                    "result": fortune_result,
                    "live2d_emotion": fortune_result.emotion,
                    "audio_url": fortune_result.audio_path
                })
```

### 3. Live2D ê°ì • ì—°ë™ ì‹œìŠ¤í…œ

**ìš´ì„¸ ê²°ê³¼ì— ë”°ë¥¸ ê°ì • ë§¤í•‘:**
```python
class FortuneEmotionMapper:
    EMOTION_MAP = {
        "excellent": {"emotion": "joy", "intensity": 5},
        "good": {"emotion": "joy", "intensity": 3},
        "normal": {"emotion": "neutral", "intensity": 2},
        "bad": {"emotion": "sadness", "intensity": 3},
        "warning": {"emotion": "fear", "intensity": 4}
    }
    
    def map_fortune_to_emotion(self, fortune_grade: str) -> dict:
        return self.EMOTION_MAP.get(fortune_grade, {"emotion": "neutral", "intensity": 1})
```

### 4. ê°œì¸í™”ëœ ìš´ì„¸ ì„œë¹„ìŠ¤

**ì‚¬ìš©ì í”„ë¡œí•„ ê¸°ë°˜ ìš´ì„¸:**
```python
class PersonalizedFortuneService:
    def __init__(self, user_profile_manager: UserProfileManager):
        self.profile_manager = user_profile_manager
    
    async def generate_personalized_fortune(self, user_id: str, fortune_type: str):
        profile = await self.profile_manager.get_profile(user_id)
        
        # ê°œì¸ ì„±í–¥ ë¶„ì„
        personality_weights = self.analyze_personality(profile)
        
        # ë§ì¶¤í˜• ìš´ì„¸ ìƒì„±
        fortune = await self.generate_fortune(
            fortune_type=fortune_type,
            personality=personality_weights,
            history=profile.fortune_history
        )
        
        return fortune
```

### 5. ë‹¤êµ­ì–´ ì§€ì› ë° í˜„ì§€í™”

**ë‹¤êµ­ì–´ ìš´ì„¸ ì‘ë‹µ:**
```python
class FortuneLocalizationService:
    def __init__(self, locale: str = "ko"):
        self.locale = locale
        self.translations = self.load_translations()
    
    async def localize_fortune_response(self, fortune_data: dict) -> dict:
        localized_response = {
            "title": self.translate(fortune_data["title_key"]),
            "description": self.translate(fortune_data["description_key"]),
            "advice": self.translate(fortune_data["advice_key"]),
            "lucky_numbers": fortune_data["lucky_numbers"],
            "lucky_colors": self.translate_colors(fortune_data["lucky_colors"])
        }
        return localized_response
```

### 6. ì„±ëŠ¥ ìµœì í™” ì „ëµ

**ìš´ì„¸ ê²°ê³¼ ìºì‹±:**
```python
class FortuneCacheManager:
    def __init__(self):
        self.daily_cache = {}  # ì¼ì¼ ìš´ì„¸ ìºì‹œ
        self.user_cache = {}   # ê°œì¸ë³„ ìºì‹œ
    
    async def get_cached_fortune(self, cache_key: str) -> Optional[dict]:
        # TTL ê¸°ë°˜ ìºì‹œ ì¡°íšŒ
        cached_data = self.daily_cache.get(cache_key)
        if cached_data and not self.is_expired(cached_data):
            return cached_data["fortune"]
        return None
    
    async def cache_fortune(self, cache_key: str, fortune_data: dict, ttl: int = 86400):
        # 24ì‹œê°„ TTLë¡œ ìºì‹±
        self.daily_cache[cache_key] = {
            "fortune": fortune_data,
            "cached_at": datetime.now(),
            "ttl": ttl
        }
```

### 7. í™•ì¥ ê°€ëŠ¥í•œ ì»¨í…ì¸  ê´€ë¦¬

**ì»¨í…ì¸  ê´€ë¦¬ ì‹œìŠ¤í…œ:**
```python
class FortuneContentManager:
    def __init__(self):
        self.content_providers = {
            "tarot": TarotContentProvider(),
            "zodiac": ZodiacContentProvider(),
            "daily": DailyContentProvider()
        }
    
    async def get_daily_content(self, content_type: str, date: datetime) -> dict:
        provider = self.content_providers[content_type]
        return await provider.generate_daily_content(date)
    
    async def update_content_database(self, content_type: str, new_content: dict):
        # ìƒˆë¡œìš´ ì»¨í…ì¸  ì—…ë°ì´íŠ¸
        provider = self.content_providers[content_type]
        await provider.update_content(new_content)
```

ì´ëŸ¬í•œ êµ¬ì¡°ë¥¼ í†µí•´ Open-LLM-VTuberì˜ ê²¬ê³ í•œ ë°±ì—”ë“œ ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Live2D ê¸°ë°˜ ìš´ì„¸ ì•±ì˜ í™•ì¥ ê°€ëŠ¥í•˜ê³  ì„±ëŠ¥ ìµœì í™”ëœ ë°±ì—”ë“œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.