#!/usr/bin/env python3
"""
Test script to verify the text cleaning bug
"""

import re

def current_broken_clean_function(text: str) -> str:
    """Current broken version of clean_text_for_tts"""
    if not text:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    original_text = text
    
    # This is the problematic emoji pattern 
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # emoticons
        "\U0001F300-\U0001F5FF"  # symbols & pictographs
        "\U0001F680-\U0001F6FF"  # transport & map symbols
        "\U0001F1E0-\U0001F1FF"  # flags (iOS)
        "\U00002702-\U000027B0"  # Miscellaneous Symbols
        "\U000024C2-\U0001F251"  # Enclosed characters - THIS IS THE PROBLEM!
        "]+", flags=re.UNICODE
    )
    text = emoji_pattern.sub('', text)
    
    # Clean up spaces
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    
    return text

def fixed_clean_function(text: str) -> str:
    """Fixed version that preserves Korean characters - matches the actual fix"""
    if not text:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    original_text = text
    
    # Properly targeted emoji pattern that doesn't include Korean characters
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # emoticons
        "\U0001F300-\U0001F5FF"  # symbols & pictographs  
        "\U0001F680-\U0001F6FF"  # transport & map symbols
        "\U0001F1E0-\U0001F1FF"  # flags (iOS)
        "\U00002702-\U000027B0"  # Miscellaneous Symbols
        "\U0001F900-\U0001F9FF"  # Supplemental Symbols and Pictographs
        "\U00002600-\U000026FF"  # Miscellaneous Symbols
        "]+", flags=re.UNICODE
    )
    text = emoji_pattern.sub('', text)
    
    # Remove specific problematic symbols for TTS
    special_symbols = ['â˜…', 'â˜†', 'â™¥', 'â™¡', 'â¤', 'ğŸ’–', 'ğŸ’•', 'ğŸ¯', 'âœ¨', 'ğŸŒŸ', 
                      'ğŸ”®', 'ğŸ´', 'ğŸƒ', 'ğŸ’«', 'â­', 'ğŸŒ™', 'â˜€', 'ğŸŒˆ', 'ğŸ’',
                      'ğŸ‘‘', 'ğŸŠ', 'ğŸ‰', 'ğŸˆ', 'ğŸ', 'ğŸŒ¹', 'ğŸŒ¸', 'ğŸŒº', 'ğŸŒ»']
    for symbol in special_symbols:
        text = text.replace(symbol, '')
    
    # Clean up spaces
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    
    # Handle empty or problematic results
    problematic_texts = [".", "..", "...", "....", ".....", ". . . .", ". . . . .", ". , . ,", ". , . , . .", "ã€€", " "]
    if not text or text in problematic_texts:
        text = "ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
    
    if len(text) < 3:
        text = "ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
    
    return text

def test_text_cleaning():
    """Test both versions with Korean text"""
    test_text = "ì˜¤ëŠ˜ì€ ì˜ì˜ˆë¡­ê³  ëª…ì˜ˆë¡œìš´ í•˜ë£¨ê°€ ë  ê²ƒì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ê¸°íšŒë¥¼ ë§Œë‚˜ê³ , ìƒì„ ë°›ì„ ê²ƒì…ë‹ˆë‹¤. ë˜í•œ, ê³ ë§ˆìš´ ì‚¬ëŒë“¤ê³¼ ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ë‚´ê²Œ ë©ë‹ˆë‹¤. ì˜¤ëŠ˜ì€ í™•ì‹ ê³¼ ê¸ì •ì— ê°€ë“í•œ í•˜ë£¨ì¼ ê²ƒì…ë‹ˆë‹¤."
    
    print(f"ì›ë³¸ í…ìŠ¤íŠ¸: '{test_text}'")
    print(f"ê¸¸ì´: {len(test_text)}")
    print()
    
    broken_result = current_broken_clean_function(test_text)
    print(f"í˜„ì¬ (ë§ê°€ì§„) ê²°ê³¼: '{broken_result}'")
    print(f"ê¸¸ì´: {len(broken_result)}")
    print()
    
    fixed_result = fixed_clean_function(test_text)
    print(f"ìˆ˜ì •ëœ ê²°ê³¼: '{fixed_result}'")  
    print(f"ê¸¸ì´: {len(fixed_result)}")
    print()
    
    # Test Korean character unicode ranges
    print("Korean character analysis:")
    for i, char in enumerate(test_text[:10]):  # Check first 10 chars
        unicode_val = ord(char)
        print(f"  '{char}': U+{unicode_val:04X} ({'Korean' if 0xAC00 <= unicode_val <= 0xD7AF else 'Other'})")

if __name__ == "__main__":
    test_text_cleaning()